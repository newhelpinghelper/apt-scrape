{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0831f0e6-942e-4695-9774-e26b6e6047c3",
   "metadata": {},
   "source": [
    "# Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5699dc-2910-4fe1-9d6f-ea0f76924568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "DEFAULT_TIMEOUT = (5, 30)  # (connect timeout, read timeout)\n",
    "\n",
    "# Load private config\n",
    "CONFIG_PATH = Path(\"config.local.json\")\n",
    "if not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing config.local.json. Copy config.example.json -> config.local.json and fill in private values.\"\n",
    "    )\n",
    "\n",
    "cfg = json.loads(CONFIG_PATH.read_text())\n",
    "\n",
    "\n",
    "BASE_URL = cfg[\"BASE_URL\"]\n",
    "FLOORPLANS_URL = BASE_URL.rstrip(\"/\") + cfg[\"FLOORPLANS_PATH\"]\n",
    "OUTPUT_CSV = cfg[\"OUTPUT_CSV\"]\n",
    "\n",
    "scraper = cloudscraper.create_scraper(browser={\"browser\": \"chrome\", \"platform\": \"darwin\", \"desktop\": True}\n",
    ")\n",
    "scraper.headers.update({\"User-Agent\": scraper.headers.get(\"User-Agent\", \"Mozilla/5.0\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8297f3-5098-410e-b180-d2b2b56930f7",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4439a7a-05b4-4cca-81a2-8784138f0c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_soup(url, timeout=DEFAULT_TIMEOUT, max_retries=3):\n",
    "    last_err = None\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = scraper.get(\n",
    "                url,\n",
    "                timeout=timeout,\n",
    "            )\n",
    "            resp.raise_for_status()\n",
    "            return BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        except (requests.exceptions.Timeout,\n",
    "                requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.ChunkedEncodingError) as e:\n",
    "            last_err = e\n",
    "            # bounded retries + backoff so you don't hammer the site\n",
    "            sleep_s = min(2 ** attempt, 10) + random.random()\n",
    "            print(f\"[fetch_soup] attempt {attempt}/{max_retries} failed for {url}: {e}. Sleeping {sleep_s:.1f}s\")\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    raise RuntimeError(f\"fetch_soup failed after {max_retries} attempts for {url}: {last_err}\")\n",
    "\n",
    "\n",
    "def get_floorplan_urls() -> dict:\n",
    "    \"\"\"\n",
    "    From the main floorplans page, find each .fp-container block,\n",
    "    grab the floorplan code from its <h2>, and the Availability link href.\n",
    "\n",
    "    Returns: {floorplan_code: absolute_url}\n",
    "    \"\"\"\n",
    "    soup = fetch_soup(FLOORPLANS_URL)\n",
    "    floorplan_urls = {}\n",
    "\n",
    "    # Each floorplan is in a div.fp-container\n",
    "    for fp_div in soup.find_all(\"div\", class_=\"fp-container\"):\n",
    "        # Get floorplan name/code from the <h3>\n",
    "        h3 = fp_div.find(\"h3\")\n",
    "        if not h3:\n",
    "            continue\n",
    "\n",
    "        code = (h3.get_text() or \"\").strip().lower().split()[0]\n",
    "\n",
    "        url = FLOORPLANS_URL + \"/\" + code\n",
    "        floorplan_urls[code] = url\n",
    "\n",
    "    return floorplan_urls\n",
    "\n",
    "\n",
    "def parse_units_from_floorplan(code: str, url: str):\n",
    "    \"\"\"\n",
    "    On a floorplan page like /floorplans/s01, extract all:\n",
    "      - unit id, e.g. \"PBA-1203\"\n",
    "      - starting price, e.g. 2535\n",
    "    Returns list of dicts.\n",
    "    \"\"\"\n",
    "    soup = fetch_soup(url)\n",
    "    units = []\n",
    "\n",
    "    # Each unit listing = <tr class=\"unit-container\">\n",
    "    for card in soup.find_all(\"tr\", class_=\"unit-container\"):\n",
    "    \n",
    "        # 1. UNIT ID\n",
    "        title = card.find(\"td\", class_=\"td-card-name\")\n",
    "        if title is None:\n",
    "            raise RuntimeError(\"Expected <td class='td-card-name'> not found — CSS may have changed\")\n",
    "    \n",
    "        unit_raw = title.get_text(strip=True)                    # \"Apartment:#PBA-1302\"\n",
    "        unit_id = re.search(r':\\W*([A-Za-z0-9-]+)', unit_raw).group(1)  # \"PBA-1302\"\n",
    "    \n",
    "        \n",
    "        # 2. SQ FT\n",
    "        sqft = card.find(\"td\", class_=\"td-card-sqft\")\n",
    "        if sqft is None:\n",
    "            raise RuntimeError(\"Expected <td class='td-card-sqft'> not found — CSS may have changed\")\n",
    "    \n",
    "        sqft_raw = sqft.get_text(strip=True)                                                # \"Sq. Ft.:513\"\n",
    "        sqft_val = re.search(r':\\W*([A-Za-z0-9,-]+)', sqft_raw).group(1).replace(\",\", \"\")   # \"513\"\n",
    "    \n",
    "        \n",
    "        # 3. PRICE\n",
    "        rent = card.find(\"td\", class_=\"td-card-rent\")\n",
    "        if rent is None:\n",
    "            raise RuntimeError(\"Expected <td class='td-card-rent'> not found — CSS may have changed\")\n",
    "    \n",
    "        rent_raw = rent.get_text(strip=True)                                                # \"Rent:$2,535\"\n",
    "        rent_val = re.search(r':\\W*([A-Za-z0-9,-]+)', rent_raw).group(1).replace(\",\", \"\")   # \"2535\"\n",
    "    \n",
    "        \n",
    "        # 4. AVAILABILITY\n",
    "        availability = card.find(\"td\", class_=\"td-card-available\")\n",
    "        if availability is None:\n",
    "            raise RuntimeError(\"Expected <td class='td-card-available'> not found — CSS may have changed\")\n",
    "    \n",
    "        availability_raw = availability.get_text(strip=True)                                                # \"Rent:$2,535\"\n",
    "        availability_val = re.search(r':\\W*([A-Za-z0-9,-]+)', availability_raw).group(1).replace(\",\", \"\")   # \"2535\"\n",
    "    \n",
    "        units.append(\n",
    "            {\n",
    "                \"date\": date.today().isoformat(),\n",
    "                \"floorplan\": code,\n",
    "                \"unit\": unit_id,\n",
    "                \"price\": rent_val,\n",
    "                \"availability\": availability_val,\n",
    "                \"url\": url,\n",
    "                \"sqft\": sqft_val\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return units\n",
    "\n",
    "def ensure_newline(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        return\n",
    "    with open(csv_path, \"rb+\") as f:\n",
    "        f.seek(-1, os.SEEK_END)\n",
    "        last = f.read(1)\n",
    "        if last != b\"\\n\":\n",
    "            f.write(b\"\\n\")\n",
    "\n",
    "\n",
    "def append_to_csv(rows, csv_path=OUTPUT_CSV):\n",
    "    if not rows:\n",
    "        print(\"No rows to append.\")\n",
    "        return\n",
    "\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "    fieldnames = [\"date\", \"floorplan\", \"unit\", \"price\", \"availability\", \"url\", \"sqft\"]\n",
    "\n",
    "    with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"raise\")\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        ensure_newline(csv_path)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"Appended {len(rows)} rows to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbf2cc-2b73-49e5-9017-99212bb5f5b6",
   "metadata": {},
   "source": [
    "# Run scrape and see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5de28-6724-4283-81a8-aef86c8f730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "floorplan_urls = get_floorplan_urls()\n",
    "print(\"Found floorplans and URLs:\")\n",
    "pprint(floorplan_urls)\n",
    "\n",
    "all_rows = []\n",
    "for code, url in floorplan_urls.items():\n",
    "    print(f\"\\nScraping units for floorplan {code} → {url}\")\n",
    "    units = parse_units_from_floorplan(code, url)\n",
    "    time.sleep(1)\n",
    "    print(f\"  Found {len(units)} units\")\n",
    "    all_rows.extend(units)\n",
    "\n",
    "print(f\"\\nTotal rows collected: {len(all_rows)}\")\n",
    "append_to_csv(all_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732261f6-4354-4ce2-a951-91f2cc24e3cf",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf15f1-6484-49d1-b6d7-381238d328de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c2324-e55f-45f9-b076-de1eb50a8aea",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ceb502-6250-4d5f-b075-5835b760baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557a08a-d71b-4552-85c7-39298fabac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"/Users/Paul/Projects/GitHub/personal-projects/projects/apt_scrape/park_bayonne_prices.csv\", index_col=False).drop_duplicates()\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adc896-6049-41e2-af3e-0d37661dc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"date\"] = pd.to_datetime(df_all[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c9b7d-7664-43a0-bb3a-086afac827f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df_all,\n",
    "    x=\"date\",\n",
    "    y=\"price\",\n",
    "    color=\"unit\",\n",
    ").update_traces(mode='lines+markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb411ab1-f2c1-4bac-a16d-23ed679095ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1048cc-b7b2-4396-8d18-a9cdbb4da397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
